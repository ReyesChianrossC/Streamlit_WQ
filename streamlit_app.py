# -*- coding: utf-8 -*-
"""Streamlit App for Water Quality Analysis

This app displays precomputed results, plots, and model comparisons from the water quality prediction pipeline.
It attempts to install required dependencies at runtime for local execution.
"""

# Step 1: Check and install dependencies
import subprocess
import sys
import importlib.util

# List of required packages
required_packages = {
    'streamlit': 'streamlit',
    'pandas': 'pandas',
    'pillow': 'Pillow',  # PIL is provided by Pillow
    'pyarrow': 'pyarrow',
    'plotly': 'plotly'
}

# Function to check and install packages
def install_package(package_name, import_name=None):
    if import_name is None:
        import_name = package_name
    if importlib.util.find_spec(import_name) is None:
        try:
            print(f"Installing {package_name}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package_name])
            print(f"{package_name} installed successfully.")
        except subprocess.CalledProcessError as e:
            print(f"Error installing {package_name}: {e}")
            sys.exit(1)

# Install missing packages
for import_name, package_name in required_packages.items():
    install_package(package_name, import_name)

# Step 2: Import dependencies after installation
import streamlit as st
import pandas as pd
import plotly.express as px
from PIL import Image
import os

# Set page configuration
st.set_page_config(page_title="Water Quality Analysis Dashboard", layout="wide")

# Define file paths
output_dir = "/content"  # Adjust as needed for your environment (e.g., '.' for local/Streamlit Cloud)
parquet_files = {
    'Combined Results': 'combined_results.parquet',
    'Weather Conditions': 'weather_conditions.parquet',
    'Wind Directions': 'wind_directions.parquet',
    'Sites': 'sites.parquet',
    'Site Summary': 'site_summary.parquet',
    'Site Predictions': 'site_predictions.parquet'
}

# Plot files mapping
plot_files = {
    'Final MAE': 'mae_comparison.png',
    'Final MSE': 'mse_comparison.png',
    'Final RMSE': 'rmse_comparison.png',
    'R2 Score': 'r2_comparison.png'
}

# Title and description
st.title("Water Quality Analysis Dashboard")
st.markdown("""
This dashboard displays precomputed results from the water quality prediction pipeline, including model performance metrics, plots, and site summaries.
""")

# Display combined results
st.header("Combined Results")
try:
    combined_results = pd.read_parquet(os.path.join(output_dir, parquet_files['Combined Results']))
    st.dataframe(combined_results, use_container_width=True)
except FileNotFoundError:
    st.error(f"Error: '{parquet_files['Combined Results']}' not found in {output_dir}. Ensure the file is generated by the prediction script.")
except Exception as e:
    st.error(f"Error loading combined results: {str(e)}")

# Display comparison plots
st.header("Comparison Plots")
for metric, plot_file in plot_files.items():
    try:
        image = Image.open(os.path.join(output_dir, plot_file))
        st.image(image, caption=f"{metric} Comparison Across Models", use_container_width=True)
    except FileNotFoundError:
        st.error(f"Error: '{plot_file}' not found in {output_dir}. Ensure the plot is generated by the prediction script.")
    except Exception as e:
        st.error(f"Error loading {metric} plot: {str(e)}")

# Display site summary
st.header("Site Summary")
try:
    site_summary = pd.read_parquet(os.path.join(output_dir, parquet_files['Site Summary']))
    st.dataframe(site_summary, use_container_width=True)
except FileNotFoundError:
    st.error(f"Error: '{parquet_files['Site Summary']}' not found in {output_dir}. Ensure the file is generated by the prediction script.")
except Exception as e:
    st.error(f"Error displaying site summary: {str(e)}")

# Model performance comparison section with bar chart
st.header("Model Performance Comparison")
try:
    # Dropdown for time horizon selection
    horizon_options = {
        'Next Week': ['Final MAE - Next Week', 'Final MSE - Next Week', 'Final RMSE - Next Week', 'R2 Score - Next Week'],
        'Next Month': ['Final MAE - Next Month', 'Final MSE - Next Month', 'Final RMSE - Next Month', 'R2 Score - Next Month'],
        'Next Year': ['Final MAE - Next Year', 'Final MSE - Next Year', 'Final RMSE - Next Year', 'R2 Score - Next Year']
    }
    selected_horizon = st.selectbox("Select Prediction Horizon", options=list(horizon_options.keys()))
    horizon_columns = horizon_options[selected_horizon]

    # Dropdown for model selection (for highlighting)
    selected_model = st.selectbox("Select Model to Highlight", options=combined_results['Model'].unique())

    # Prepare comparison DataFrame
    comparison_df = combined_results[['Model'] + horizon_columns].copy()
    # Convert to numeric for plotting
    for col in horizon_columns:
        comparison_df[col] = pd.to_numeric(comparison_df[col], errors='coerce')

    # Highlight the selected model's row in the table
    def highlight_selected_model(row):
        return ['background-color: #a9a9a9' if row['Model'] == selected_model else '' for _ in row]

    st.subheader(f"Model Comparison for {selected_horizon} Prediction")
    st.dataframe(comparison_df.style.apply(highlight_selected_model, axis=1), use_container_width=True)

    # Create grouped bar chart
    plot_df = comparison_df.melt(id_vars='Model', var_name='Metric', value_name='Value')
    fig = px.bar(plot_df,
                 x='Model',
                 y='Value',
                 color='Metric',
                 barmode='group',
                 title=f"Model Comparison for {selected_horizon} Prediction",
                 labels={'Value': 'Metric Value', 'Model': 'Model'},
                 height=500)
    st.plotly_chart(fig, use_container_width=True)

    # Display the selected model's metrics explicitly
    selected_model_metrics = comparison_df[comparison_df['Model'] == selected_model]
    st.markdown(f"**Selected Model ({selected_model}) Metrics for {selected_horizon}:**")
    for metric, value in selected_model_metrics[horizon_columns].iloc[0].items():
        st.markdown(f"- {metric}: {value:.3f}")
except Exception as e:
    st.error(f"Error displaying model comparison: {str(e)}")

# Footer
st.markdown("""
---
**Note**: Ensure all required files (Parquet and PNGs) are included in the `/content` directory.
To run locally, this script will attempt to install dependencies automatically. If it fails, install them manually with:
`pip install streamlit pandas pillow pyarrow plotly` and execute `streamlit run streamlit_app.py`.
For Streamlit Cloud, include a `requirements.txt` with the following packages in your GitHub repository:
```
streamlit
pandas
pillow
pyarrow
plotly
```
""")
